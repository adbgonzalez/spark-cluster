{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81e652c-2fef-4948-9f4d-9dd6cb3cda9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using packages ['org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0', 'org.apache.kafka:kafka-clients:3.5.1']\n"
     ]
    }
   ],
   "source": [
    "# Inicialización del objeto SparkSession para Kafka\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "import os\n",
    "import pyspark\n",
    "\n",
    "scala_version = '2.12'  # TODO: Ensure this is correct\n",
    "spark_version = pyspark.__version__\n",
    "\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.5.1'\n",
    "]\n",
    "\n",
    "args = os.environ.get('PYSPARK_SUBMIT_ARGS', '')\n",
    "if not args:\n",
    "    args = f'--packages {\",\".join(packages)}'\n",
    "    print('Using packages', packages)\n",
    "    os.environ['PYSPARK_SUBMIT_ARGS'] = f'{args} pyspark-shell'\n",
    "else:\n",
    "    print(f'Found existing args: {args}') \n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "   .master(\"local\")\\\n",
    "   .appName(\"kafka-example\")\\\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bead5522-9300-47e5-a821-15795316f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscribe to 1 topic\n",
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka-1:9092\") \\\n",
    "  .option(\"subscribe\", \"entrada\") \\\n",
    "  .option('includeTimestamp', 'true')\\\n",
    "  .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bed51d-71f9-46e5-86ab-861163c28e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70284c67-f13a-4872-a72f-a7fd389e1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split\n",
    "dfPalabras = df.select(\n",
    "    explode(split(df.value, ' ')).alias('palabra'),\n",
    "    df.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703873fb-cc56-4ac1-8078-5c436b8b3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPalabras.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29f4837-27de-4817-965b-9f8356dce421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window\n",
    "windowedCounts = dfPalabras\\\n",
    "    .withWatermark(\"timestamp\", \"2 minutes\") \\\n",
    "    .groupBy(\n",
    "       window(dfPalabras.timestamp, \"2 minutes\", \"1 minutes\"), dfPalabras.palabra\n",
    "    ).count().orderBy('window')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a1bbda-6a88-4f17-8c17-531cf07411a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = true)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- palabra: string (nullable = false)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowedCounts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e2fef-a582-4533-a68c-46185333af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "kafka_output_topic = \"salidaw\"\n",
    "\n",
    "kafka_output_config = {\n",
    "    \"kafka.bootstrap.servers\": \"kafka-1:9092\",  # Coloca aquí los servidores de arranque de Kafka\n",
    "    \"topic\": kafka_output_topic\n",
    "}\n",
    "\n",
    "query2 = windowedCounts \\\n",
    "    .selectExpr(\"CAST(palabra AS STRING) AS key\", \"to_json(struct(*)) AS value\") \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .options(**kafka_output_config) \\\n",
    "    .option(\"checkpointLocation\", \"/home/jovyan/checkpoints\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf6a973-37d6-47a5-af72-a36b585664c7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Start running the query that prints the running counts to the console\n",
    "query = windowedCounts \\\n",
    "          .writeStream \\\n",
    "          .outputMode(\"complete\") \\\n",
    "          .format(\"memory\") \\\n",
    "          .queryName(\"consulta1\") \\\n",
    "          .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a5461-5c5f-4a96-a795-4b7d2a6967f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+\n",
      "|              window|palabra|count|\n",
      "+--------------------+-------+-----+\n",
      "|{2024-04-25 20:14...|   hola|    1|\n",
      "|{2024-04-25 20:15...|   hola|    1|\n",
      "+--------------------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from time import sleep\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    display(query.status)\n",
    "    display(spark.sql('SELECT * FROM consulta1').show())\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb52c31-32fc-4f8d-abe6-1875d68a934d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
